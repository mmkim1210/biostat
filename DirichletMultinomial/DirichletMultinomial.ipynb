{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet-multinomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability mass function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In RNA-seq, for example, [count data](https://arxiv.org/abs/2001.04343) is commonly modeled using a Dirichlet-multinomial distribution, where the multinomial probabilities $\\mathbf{p} = (p_1,\\ldots, p_d)^T$ follow a Dirichlet distribution with the parameter vector $\\boldsymbol{\\alpha} = (\\alpha_1,\\ldots, \\alpha_d)^T$ and probability density function (pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pi(\\mathbf{p}) =  \\frac{\\Gamma(|\\boldsymbol \\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\prod_{j=1}^d p_j^{\\alpha_j-1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha_j>0$ and $|\\boldsymbol \\alpha|=\\sum_{j=1}^d \\alpha_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $\\pi(\\mathbf{p})$ is a pdf, $\\int_{\\Delta_d} \\pi(\\mathbf{p}) d \\mathbf{p} = 1$ and hence $\\int_{\\Delta_d} \\prod_{j=1}^d p_j^{\\alpha_j-1} d \\mathbf{p} = \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j)}{\\Gamma(|\\boldsymbol \\alpha|)}$, where $\\Delta_d$ is the unit simplex in $d$ dimensions. Using this property, it is straightforward to show that $\\mathbb{E}[p_j] = \\frac{\\alpha_j}{|\\boldsymbol \\alpha|}$ and $\\mathbb{E}[p_j^2] = \\frac{\\alpha_j(\\alpha_j + 1)}{|\\boldsymbol \\alpha|(|\\boldsymbol \\alpha| + 1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for a multivariate count vector $\\mathbf{x}=(x_1, \\ldots, x_d)^T$ with batch size $|\\mathbf{x}|=\\sum_{j=1}^d x_j$, the probability mass function (pmf) for Dirichlet-multinomial distribution is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(\\mathbf{x} \\mid \\boldsymbol \\alpha) = \\int_{\\Delta_d} f(\\mathbf{x} \\mid \\mathbf{p}, \\boldsymbol \\alpha) \\cdot \\pi(\\mathbf{p}) d \\mathbf{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\int_{\\Delta_d} \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\prod_{j=1}^d p_j^{x_j} \\cdot \\pi(\\mathbf{p}) \\, d \\mathbf{p}  \n",
    "= \\binom{|\\mathbf{x}|}{\\mathbf{x}} \\frac{\\prod_{j=1}^d \\Gamma(\\alpha_j+x_j)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)} \\frac{\\Gamma(|\\boldsymbol \\alpha|)}{\\Gamma(|\\boldsymbol \\alpha|+|\\mathbf{x}|)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given independent data points $\\mathbf{x}_1, \\ldots, \\mathbf{x}_n$, the log-likelihood is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\alpha) = \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i} + \\sum_{i=1}^n \\sum_{j=1}^d [\\ln \\Gamma(\\alpha_j + x_{ij}) - \\ln \\Gamma(\\alpha_j)] - \\sum_{i=1}^n [\\ln \\Gamma(|\\boldsymbol \\alpha|+|\\mathbf{x}_i|) - \\ln \\Gamma(|\\boldsymbol \\alpha|)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\sum_{i=1}^n \\ln \\binom{|\\mathbf{x}_i|}{\\mathbf{x}_i}\n",
    "+\\sum_{i=1}^n \\sum_{j=1}^d \\sum_{k=0}^{x_{ij}-1} \\ln(\\alpha_j+k) - \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\ln(|\\boldsymbol \\alpha|+k).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last equality holds, since $\\frac{\\Gamma(a + k)}{\\Gamma(a)} = a (a + 1) \\cdots (a+k-1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient and Hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $\\frac{\\partial}{\\partial x} \\ln \\Gamma(x) = \\frac{\\Gamma'(x)}{\\Gamma(x)} = \\Psi(x)$ and $\\frac{\\partial^2}{\\partial x^2} \\ln \\Gamma(x) = \\Psi'(x)$, the score function is $\\nabla L(\\boldsymbol \\alpha) = d L(\\boldsymbol \\alpha)^T$, where "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\alpha_j} L(\\alpha) = \\sum_{i=1}^n [\\Psi(\\alpha_j + x_{ij}) - \\Psi(\\alpha_j)] - \\sum_{i=1}^n [\\Psi(|\\boldsymbol \\alpha|+|\\mathbf{x}_i|) - \\Psi(|\\boldsymbol \\alpha|)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\sum_{i=1}^n \\sum_{k=0}^{x_{ij}-1} \\frac{1}{\\alpha_j+k} - \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{|\\boldsymbol \\alpha|+k}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed information is $-\\nabla^2L(\\alpha) = - d^2 L(\\boldsymbol \\alpha)$, where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "-\\frac{\\partial^2}{\\partial \\alpha_j \\partial \\alpha_k} L(\\alpha) = \n",
    "\\begin{cases}\n",
    "- \\sum_{i=1}^n [\\Psi'(\\alpha_j + x_{ij}) - \\Psi'(\\alpha_j)] + \\sum_{i=1}^n [\\Psi'(|\\boldsymbol \\alpha|+|\\mathbf{x}_i|) - \\Psi'(|\\boldsymbol \\alpha|)], & k = j \\\\\n",
    "\\sum_{i=1}^n [\\Psi'(|\\boldsymbol \\alpha|+|\\mathbf{x}_i|) - \\Psi'(|\\boldsymbol \\alpha|)], & k \\neq j\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^n \\sum_{k=0}^{x_{ij}-1} \\frac{1}{(\\alpha_j+k)^2} - \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{(|\\boldsymbol \\alpha|+k)^2}, & k = j \\\\\n",
    "- \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{(|\\boldsymbol \\alpha|+k)^2}, & k \\neq j\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the log-likelihood is not a concave function, since $-\\frac{\\partial^2}{\\partial \\alpha_1^2} L(\\alpha) = - \\sum_{i=1}^n [\\Psi'(\\alpha_1 + x_{i1}) - \\Psi'(\\alpha_1)] + \\sum_{i=1}^n [\\Psi'(|\\boldsymbol \\alpha|+|\\mathbf{x}_i|) - \\Psi'(|\\boldsymbol \\alpha|)]$ could be negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected Fisher information is $\\mathbb{E}[-\\nabla^2L(\\alpha)]$, where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}\\big[-\\frac{\\partial^2}{\\partial \\alpha_j \\partial \\alpha_k} L(\\alpha)\\big] = \n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^n \\sum_{x_{ij}=0}^{x_{ij}=|\\boldsymbol{x_i}|} \\sum_{k=0}^{x_{ij}-1} \\frac{1}{(\\alpha_j+k)^2} f(x_{ij}) - \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{(|\\boldsymbol \\alpha|+k)^2}, & k = j \\\\\n",
    "- \\sum_{i=1}^n \\sum_{k=0}^{|\\mathbf{x}_i|-1} \\frac{1}{(|\\boldsymbol \\alpha|+k)^2}, & k \\neq j\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and $f(x_{ij})$ is the marginal distribution of $f(\\boldsymbol{x})$ for $x_{ij}$. Here, Fisher scoring method is inefficient for computing maximum likelihood estimator (MLE), since calculation of the expected information matrix is difficult. So we instead use a positive definite matrix that is approximated from the observed information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $(p_1,\\ldots,p_d) \\in \\Delta_d = \\{\\mathbf{p}: p_i \\ge 0, \\sum_i p_i = 1\\}$ follows a Dirichlet distribution with parameter $\\alpha = (\\alpha_1,\\ldots,\\alpha_d)$. Then taking the derivative with respect to $\\alpha_k$ on both sides, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_{\\Delta_d}\\frac{\\Gamma(|\\boldsymbol \\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\rightarrow \\frac{\\partial}{\\partial \\alpha_k}\\int_{\\Delta_d}\\frac{\\Gamma(|\\alpha|)}{\\prod_{j=1}^d \\Gamma(\\alpha_j)}\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p} = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\int_{\\Delta_d}\\bigg(\\frac{\\Gamma'(|\\boldsymbol \\alpha|)\\prod_{j=1}^{d}\\Gamma(\\alpha_j)-\\Gamma(|\\boldsymbol \\alpha|)\\Gamma'(\\alpha_k)\\prod_{j\\neq k}^{d}\\Gamma(\\alpha_j)}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)^{2}}\\bigg)\\prod_{j=1}^d p_j^{\\alpha_j-1}+\\frac{\\Gamma(|\\boldsymbol \\alpha|)}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)}\\ln(p_k)\\prod_{j=1}^d p_j^{\\alpha_j-1} \\, d\\mathbf{p}=0\\\\\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\therefore \\mathbb{E}\\big[\\ln(p_k)\\big] = \\int_{\\Delta_d}\\bigg(\\frac{\\Gamma(|\\boldsymbol \\alpha|)\\Gamma'(\\alpha_k)\\prod_{j\\neq k}^{d}\\Gamma(\\alpha_j)-\\Gamma'(|\\boldsymbol \\alpha|)\\prod_{j=1}^{d}\\Gamma(\\alpha_j)}{\\prod_{j=1}^{d}\\Gamma(\\alpha_j)^{2}}\\bigg)\\prod_{j=1}^d p_j^{\\alpha_j-1}d\\mathbf{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{\\Gamma'(\\alpha_k)}{\\Gamma(\\alpha_k)} - \\frac{\\Gamma'(|\\boldsymbol \\alpha|)}{\\Gamma(|\\boldsymbol \\alpha|)} \n",
    "= \\Psi(\\alpha_k) - \\Psi(|\\boldsymbol \\alpha|).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Hessian matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed information matrix is not positive definite as mentioned above, but it takes the Woodbury form, which we can take advantage of to approximate a positive definite matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of moment estimator for $\\boldsymbol{\\alpha}$ would be a good starting point for iterative algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Newton's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SpecialFunctions\n",
    "polygamma(0, 0.5)  # digamma(0.5)\n",
    "polygamma(1, 0.5);  # trigamma(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dirmult_logpdf"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    dirmult_logpdf(x::Vector, α::Vector)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at data point `x`.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(x::Vector, α::Vector)\n",
    "    xsum = sum(x)\n",
    "    αsum = sum(α)\n",
    "    loglike = logfactorial(xsum)\n",
    "    for j in 1:length(x)\n",
    "        loglike = loglike - logfactorial(x[j]) + loggamma(α[j] + x[j]) - loggamma(α[j])\n",
    "    end\n",
    "    loglike = loglike - loggamma(xsum + αsum) + loggamma(αsum)\n",
    "    return loglike\n",
    "end\n",
    "\n",
    "function dirmult_logpdf!(r::Vector, X::Matrix, α::Vector)\n",
    "    for i in 1:size(X, 2)\n",
    "        r[i] = dirmult_logpdf(X[:, i], α)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dirmult_logpdf(X, α)\n",
    "    \n",
    "Compute the log-pdf of Dirichlet-multinomial distribution with parameter `α` \n",
    "at each data point in `X`. Each column of `X` is one data point.\n",
    "\"\"\"\n",
    "function dirmult_logpdf(X::Matrix, α::Vector)\n",
    "    r = zeros(size(X, 2))\n",
    "    dirmult_logpdf!(r, X, α)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we build a classifer for handwritten digit recognition. Following figure shows example bitmaps of handwritten digits from U.S. postal envelopes. \n",
    "\n",
    "<img src=\"./handwritten_digits.png\" width=\"250\" align=\"center\"/>\n",
    "\n",
    "Each digit is represented by a $32 \\times 32$ bitmap in which each element indicates one pixel with a value of white or black. Each $32 \\times 32$ bitmap is divided into blocks of $4 \\times 4$, and the number of white pixels are counted in each block. Therefore each handwritten digit is summarized by a vector $\\mathbf{x} = (x_1, \\ldots, x_{64})$ of length 64 where each element is a count between 0 and 16. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 65)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DelimitedFiles\n",
    "using LinearAlgebra\n",
    "\n",
    "optdigits = readdlm(\"./optdigits.tra\", ',', Int64)\n",
    "size(optdigits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = copy(transpose(optdigits[:, 1:64]))\n",
    "digits = optdigits[:, 65];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of 3823 handwritten digits. Each row contains the 64 counts of a digit and the last element (65th element) indicates what digit it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirmult_logpdf(data, ones(size(data, 1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.6.0\n",
      "Commit f9720dc2eb (2021-03-24 12:55 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.6.0)\n",
      "  CPU: Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-11.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "65px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
