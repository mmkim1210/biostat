{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9a5c2d",
   "metadata": {},
   "source": [
    "# Generalized linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d623ab9",
   "metadata": {},
   "source": [
    "There are two essential components for generalized linear model (GLM): a distribution for response $Y_i$ and a link function that relates the mean of $Y_i$ to its covariates $X_i$.\n",
    "\n",
    "### Exponential family distribution\n",
    "In GLM, the distribution of $Y_i$ is from the exponential familty of distributions of form\n",
    "$$\n",
    "  f(y \\mid \\theta, \\phi) = \\exp \\left[ \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right],\n",
    "$$\n",
    "where $\\theta$ is called the **canonical parameter** or **natural parameter** and represents the location, while $\\phi$ is the **dispersion parameter** and represents the scale. Note that the canonical parameter $\\theta$ is not necessarily the mean $\\mu$. Examples of the exponential family distribution include normal, inverse normal, binomial, Poisson, and gamma distributions. An exponential family distribution have the following mean and variance.\n",
    "\\begin{eqnarray*}\n",
    "  \\int f(y \\mid \\theta, \\phi) \\ dy &=& \\int \\exp \\left[ \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right] dy \n",
    "  = 1\\\\\n",
    "  \\frac{\\partial}{\\partial \\theta} \\int f(y \\mid \\theta, \\phi) \\ dy &=& \n",
    "  \\int \\frac{\\partial}{\\partial \\theta} \\ f(y \\mid \\theta, \\phi) \\ dy = 0 \\\\\n",
    "  &=& \\int \\frac{y - b'(\\theta)}{a(\\phi)} \\exp \\left[ \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right] dy \\\\\n",
    "  \\therefore \\mathbb{E}Y &=& \\mu = b'(\\theta) \\\\\n",
    "  \\frac{\\partial^2}{\\partial \\theta^2} \\int f(y \\mid \\theta, \\phi) \\ dy &=& \n",
    "  \\int \\frac{\\partial^2}{\\partial \\theta^2} \\ f(y \\mid \\theta, \\phi) \\ dy = 0 \\\\\n",
    "  &=& \\int \\frac{(y - b'(\\theta))^2 - b''(\\theta)a(\\phi)}{a(\\phi)^2} \n",
    "  \\exp \\left[ \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right] dy \\\\ \n",
    "  &=& \\int \\frac{y^2 - 2 y b'(\\theta) + b'(\\theta)^2 - b''(\\theta)a(\\phi)}{a(\\phi)^2} \n",
    "  \\exp \\left[ \\frac{y \\theta - b(\\theta)}{a(\\phi)} + c(y, \\phi) \\right] dy \\\\ \n",
    "  \\mathbb{E}Y^2 &=& b'(\\theta)^2 + b''(\\theta)a(\\phi) \\\\\n",
    "  \\therefore \\operatorname{Var}Y &=& \\sigma^2 = b''(\\theta) a(\\phi)\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6ba58",
   "metadata": {},
   "source": [
    "### Link function\n",
    "\n",
    "Given the linear predictor (or systematic component) $\\eta = \\mathbf{x}^T \\boldsymbol{\\beta}$, \n",
    "a link function, $g$, relates the mean $\\mathbb{E} Y = \\mu$ to the covariates $\\eta = g(\\mu)$. In principal, any monotone, continuous, and differentiable function can be a link function. For example, for binomial distribution, logit, probit, complementary log-log, and Cauchit link functions are viable choices. The **canonical link** has $g$ such that $\\eta = g(\\mu) = g(b'(\\theta)) =\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c761c5",
   "metadata": {},
   "source": [
    "### Fisher scoring algorithm\n",
    "\n",
    "GLM regression coefficients are estimated by MLE. Recall that the Newton-Raphson algorithm for maximizing a log-likelihood $\\ell(\\boldsymbol{\\beta})$ proceeds as\n",
    "$$\n",
    "  \\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + s [- \\nabla^2 \\ell(\\boldsymbol{\\beta}^{(t)})]^{-1} \\nabla \\ell(\\boldsymbol{\\beta}^{(t)}),\n",
    "$$\n",
    "where $s>0$ is a step length, $\\nabla \\ell$ is the score (gradient) vector, and $-\\nabla^2 \\ell$ is the observed information matrix (negative Hessian). For GLM, we can use the chain rule $\\frac{\\partial}{\\partial \\boldsymbol{\\beta}} = \\frac{\\partial}{\\partial \\theta_i} \\frac{\\partial \\theta_i}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\boldsymbol{\\beta}}$ and $\\mu_i = b'(\\theta_i), \\sigma_i^2 = b''(\\theta_i) a(\\phi), \\eta_i = \\mathbf{x}_i^T \\beta = g(\\mu_i), \\frac{\\partial \\mu_i}{\\partial \\theta_i} = b''(\\theta_i)$ to derive\n",
    "\\begin{eqnarray*}\n",
    "  \\ell(\\boldsymbol{\\beta}) &=& \\sum_{i=1}^n \\frac{y_i \\theta_i - b(\\theta_i)}{a(\\phi)} + c(y_i, \\phi) \\\\\n",
    "  \\nabla \\ell(\\boldsymbol{\\beta}) &=& \\sum_{i=1}^n \\frac{(y_i - \\mu_i)}{a(\\phi)} \n",
    "  \\frac{1}{b''(\\theta_i)} \\mu_i'(\\eta_i) \\mathbf{x}_i = \n",
    "  \\sum_{i=1}^n \\frac{(y_i - \\mu_i) \\mu_i'(\\eta_i)}{\\sigma_i^2} \\mathbf{x}_i \\\\\n",
    "  - \\nabla^2 \\ell(\\boldsymbol{\\beta}) &=& \\sum_{i=1}^n \\frac{[\\mu_i'(\\eta_i)]^2}{\\sigma_i^2} \\mathbf{x}_i\n",
    "  \\mathbf{x}_i^T - \\sum_{i=1}^n \\frac{(y_i - \\mu_i) \\mu_i''(\\eta_i)}{\\sigma_i^2} \\mathbf{x}_i \\mathbf{x}_i^T \\\\\n",
    "  & & + \\sum_{i=1}^n \\frac{(y_i - \\mu_i) [\\mu_i'(\\eta_i)]^2 (d \\sigma_i^{2} / d\\mu_i)}{\\sigma_i^4} \\mathbf{x}_i\n",
    "  \\mathbf{x}_i^T. \\\\\n",
    "\\end{eqnarray*}\n",
    "For GLMs with canonical links, the second term and third term cancel using the following\n",
    "$$\n",
    "\\frac{d\\mu_i}{d \\eta_i} = \\frac{d\\mu_i}{d \\theta_i} = \\frac{d \\, b'(\\theta_i)}{d \\theta_i} = b''(\\theta_i) = \\frac{\\sigma_i^2}{a(\\phi)}.\n",
    "$$\n",
    "Therefore for canonical link the negative Hessian is positive semidefinte and Newton's algorithm with line search is stable. Meanwhile, for non-canonical link, we can use the expected (Fisher) information matrix\n",
    "$$\n",
    "  \\mathbb{E} [- \\nabla^2 \\ell(\\boldsymbol{\\beta})] = \\sum_{i=1}^n \\frac{[\\mu_i'(\\eta_i)]^2}{\\sigma_i^2} \\mathbf{x}_i \\mathbf{x}_i^T = \\mathbf{X}^T \\mathbf{W} \\mathbf{X} \\succeq 0,\n",
    "$$\n",
    "where $\\mathbf{W} = \\text{diag}([\\mu_i'(\\eta_i)]^2/\\sigma_i^2)$. This modified Newton-Raphson algorithm is called the **Fisher scoring algorithm**. \n",
    "The Fisher scoring algorithmn proceeds as\n",
    "\\begin{eqnarray*}\n",
    "  \\boldsymbol{\\beta}^{(t+1)} &=& \\boldsymbol{\\beta}^{(t)} + s(\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T (\\mathbf{y} - \\widehat{\\boldsymbol{\\mu}}^{(t)}) \\\\\n",
    "  &=& (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} [\\mathbf{X} \\boldsymbol{\\beta}^{(t)} + s (\\mathbf{W}^{(t)})^{-1} (\\mathbf{y} - \\widehat{\\boldsymbol{\\mu}}^{(t)})] \\\\\n",
    "  &=& (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{z}^{(t)},\n",
    "\\end{eqnarray*} \n",
    "where\n",
    "$$\n",
    "  \\mathbf{z}^{(t)} = \\mathbf{X} \\boldsymbol{\\beta}^{(t)} + s (\\mathbf{W}^{(t)})^{-1} (\\mathbf{y} - \\widehat{\\boldsymbol{\\mu}}^{(t)})\n",
    "$$\n",
    "are working responses. In this sense, the Fisher scoring algorithm for GLM is also called the IRWLS (iteratively reweighted least squares).\n",
    "\n",
    "\n",
    "### Hypothesis testing\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
